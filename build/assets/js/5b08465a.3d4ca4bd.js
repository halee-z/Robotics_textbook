"use strict";(globalThis.webpackChunkeducational_ai_humanoid_robotics=globalThis.webpackChunkeducational_ai_humanoid_robotics||[]).push([[910],{1503:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>_,frontMatter:()=>i,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"humanoid-robotics/control-systems","title":"Control Systems for Humanoid Robots","description":"Overview","source":"@site/docs/humanoid-robotics/control-systems.md","sourceDirName":"humanoid-robotics","slug":"/humanoid-robotics/control-systems","permalink":"/educational-ai-humanoid-robotics/docs/humanoid-robotics/control-systems","draft":false,"unlisted":false,"editUrl":"https://github.com/educational-ai-humanoid-robotics/educational-ai-humanoid-robotics.github.io/tree/main/packages/create-docusaurus/templates/shared/docs/humanoid-robotics/control-systems.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Robot Kinematics: Structure and Motion","permalink":"/educational-ai-humanoid-robotics/docs/humanoid-robotics/kinematics"},"next":{"title":"Humanoid Robot Walking Algorithms and Gait Generation","permalink":"/educational-ai-humanoid-robotics/docs/humanoid-robotics/walking-algorithms"}}');var o=t(4848),a=t(8453);const i={sidebar_position:2},s="Control Systems for Humanoid Robots",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Control Architecture Hierarchy",id:"control-architecture-hierarchy",level:2},{value:"Zero Moment Point (ZMP) Theory",id:"zero-moment-point-zmp-theory",level:2},{value:"Mathematical Foundation",id:"mathematical-foundation",level:3},{value:"Linear Inverted Pendulum Model (LIPM)",id:"linear-inverted-pendulum-model-lipm",level:2},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:2},{value:"Preview Control Approach",id:"preview-control-approach",level:3},{value:"Whole-Body Control Framework",id:"whole-body-control-framework",level:2},{value:"Stability Analysis and Control",id:"stability-analysis-and-control",level:2},{value:"Lyapunov Stability for Walking",id:"lyapunov-stability-for-walking",level:3},{value:"Adaptive Control for Humanoid Robots",id:"adaptive-control-for-humanoid-robots",level:2},{value:"Model Reference Adaptive Control (MRAC)",id:"model-reference-adaptive-control-mrac",level:3},{value:"Safety and Fault Tolerance",id:"safety-and-fault-tolerance",level:2},{value:"Balance Recovery Control",id:"balance-recovery-control",level:3},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"control-systems-for-humanoid-robots",children:"Control Systems for Humanoid Robots"})}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"Control systems for humanoid robots are fundamentally more complex than traditional robotics due to the need for dynamic balance, multi-degree-of-freedom coordination, and real-time stability. Unlike wheeled or stationary robots, humanoid robots must manage their center of mass while performing tasks, making control design one of the most challenging aspects of humanoid robotics."}),"\n",(0,o.jsx)(n.h2,{id:"control-architecture-hierarchy",children:"Control Architecture Hierarchy"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid control systems typically employ a hierarchical architecture with multiple layers:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"High-Level Planning (1-10 Hz)\n\u251c\u2500\u2500 Walking pattern generation\n\u251c\u2500\u2500 Task planning and sequencing  \n\u251c\u2500\u2500 Footstep planning\n\u2514\u2500\u2500 Trajectory optimization\n\nMid-Level Control (50-200 Hz)\n\u251c\u2500\u2500 Balance control and recovery\n\u251c\u2500\u2500 Trajectory generation\n\u251c\u2500\u2500 Contact planning\n\u2514\u2500\u2500 Whole-body control\n\nLow-Level Control (100-1000 Hz)\n\u251c\u2500\u2500 Joint position/velocity control\n\u251c\u2500\u2500 Torque control\n\u251c\u2500\u2500 Sensor feedback processing\n\u2514\u2500\u2500 Safety monitoring\n"})}),"\n",(0,o.jsx)(n.h2,{id:"zero-moment-point-zmp-theory",children:"Zero Moment Point (ZMP) Theory"}),"\n",(0,o.jsx)(n.p,{children:"The Zero Moment Point (ZMP) is a fundamental concept in humanoid robotics that describes the point on the ground where the moment of the ground reaction force is zero. For a humanoid robot to maintain dynamic equilibrium, the ZMP must remain within the support polygon (usually the area defined by the feet)."}),"\n",(0,o.jsx)(n.h3,{id:"mathematical-foundation",children:"Mathematical Foundation"}),"\n",(0,o.jsx)(n.p,{children:"For a robot with center of mass (CoM) at position (x_com, y_com, z_com):"}),"\n",(0,o.jsx)(n.p,{children:"ZMP_x = x_com - (z_com/g) * x_com_dd\nZMP_y = y_com - (z_com/g) * y_com_dd"}),"\n",(0,o.jsx)(n.p,{children:"Where:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"g is gravitational acceleration"}),"\n",(0,o.jsx)(n.li,{children:"x_com_dd and y_com_dd are the second derivatives (acceleration) of the CoM position"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\nfrom math import sqrt\n\nclass ZMPController:\n    def __init__(self, com_height=0.8, gravity=9.81):\n        """\n        Initialize ZMP controller with robot parameters\n        \n        Args:\n            com_height: Initial estimate of center of mass height (meters)\n            gravity: Gravitational acceleration (m/s^2)\n        """\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = sqrt(gravity / com_height)  # Natural frequency parameter\n        \n        # ZMP tracking error integral for PID control\n        self.zmp_error_integral = np.array([0.0, 0.0])\n        self.prev_zmp_error = np.array([0.0, 0.0])\n        \n        # PID controller parameters\n        self.kp = 10.0  # Proportional gain\n        self.ki = 1.0   # Integral gain\n        self.kd = 2.0   # Derivative gain\n        \n        # Support polygon (simplified as rectangle for dual support)\n        self.support_polygon = {\n            "x_range": [-0.1, 0.1],   # 20cm in x direction\n            "y_range": [-0.15, 0.15]  # 30cm in y direction\n        }\n        \n    def calculate_zmp(self, com_pos, com_acc):\n        """\n        Calculate ZMP from current CoM position and acceleration\n        \n        Args:\n            com_pos: [x, y, z] position of center of mass\n            com_acc: [x, y, z] acceleration of center of mass\n            \n        Returns:\n            [x, y] ZMP coordinates\n        """\n        x_com, y_com, z_com = com_pos\n        x_acc, y_acc, z_acc = com_acc\n        \n        zmp_x = x_com - (z_com / self.gravity) * x_acc\n        zmp_y = y_com - (z_com / self.gravity) * y_acc\n        \n        return np.array([zmp_x, zmp_y])\n    \n    def is_stable(self, zmp):\n        """\n        Check if ZMP is within support polygon\n        \n        Args:\n            zmp: [x, y] ZMP coordinates\n            \n        Returns:\n            Boolean indicating stability\n        """\n        zmp_x, zmp_y = zmp\n        x_min, x_max = self.support_polygon["x_range"]\n        y_min, y_max = self.support_polygon["y_range"]\n        \n        return x_min <= zmp_x <= x_max and y_min <= zmp_y <= y_max\n    \n    def balance_control(self, current_zmp, desired_zmp, dt=0.01):\n        """\n        Generate balance control commands using ZMP feedback\n        \n        Args:\n            current_zmp: [x, y] current ZMP position\n            desired_zmp: [x, y] desired ZMP position (usually center of support polygon)\n            dt: Time step for integration\n            \n        Returns:\n            Control output for CoM adjustment\n        """\n        # Calculate ZMP error\n        zmp_error = desired_zmp - current_zmp\n        \n        # Update integral term with anti-windup\n        self.zmp_error_integral += zmp_error * dt\n        # Limit integral windup\n        self.zmp_error_integral = np.clip(self.zmp_error_integral, -1.0, 1.0)\n        \n        # Calculate derivative term\n        zmp_error_derivative = (zmp_error - self.prev_zmp_error) / dt if dt > 0 else np.array([0.0, 0.0])\n        \n        # PID control law\n        control_output = (self.kp * zmp_error + \n                         self.ki * self.zmp_error_integral + \n                         self.kd * zmp_error_derivative)\n        \n        # Store previous error for next derivative calculation\n        self.prev_zmp_error = zmp_error\n        \n        # Limit control output to reasonable values\n        control_output = np.clip(control_output, -0.5, 0.5)  # Limit to 50cm adjustment\n        \n        return control_output\n    \n    def update_com_height(self, new_height):\n        """\n        Update CoM height when it changes (e.g., during walking)\n        \n        Args:\n            new_height: New CoM height estimate\n        """\n        self.com_height = new_height\n        self.omega = sqrt(self.gravity / self.com_height)\n\n# Example usage\nzmp_ctrl = ZMPController(com_height=0.85)\n\n# Simulate balance control\ncurrent_zmp = np.array([0.05, 0.02])  # Slightly off-center\ndesired_zmp = np.array([0.0, 0.0])    # Center of support polygon\ndt = 0.01  # 100Hz control\n\ncontrol_output = zmp_ctrl.balance_control(current_zmp, desired_zmp, dt)\nprint(f"Current ZMP: {current_zmp}")\nprint(f"Desired ZMP: {desired_zmp}")\nprint(f"Control output: {control_output}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"linear-inverted-pendulum-model-lipm",children:"Linear Inverted Pendulum Model (LIPM)"}),"\n",(0,o.jsx)(n.p,{children:"The Linear Inverted Pendulum Model is a simplified representation of bipedal walking that assumes the robot's center of mass moves at a constant height:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\u1e8d = \u03c9\xb2(x - x_zmp)\n"})}),"\n",(0,o.jsx)(n.p,{children:"Where \u03c9 = \u221a(g/h) and h is the CoM height."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom scipy.integrate import odeint\n\nclass LinearInvertedPendulum:\n    def __init__(self, com_height=0.8, gravity=9.81):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        \n    def dynamics(self, state, t, zmp_position):\n        """\n        Define the dynamics of the inverted pendulum\n        \n        Args:\n            state: [x_position, x_velocity, y_position, y_velocity]\n            t: Time\n            zmp_position: [zmp_x, zmp_y] current ZMP position\n        """\n        x, dx, y, dy = state\n        zmp_x, zmp_y = zmp_position\n        \n        # LIPM dynamics\n        ddx = self.omega**2 * (x - zmp_x)\n        ddy = self.omega**2 * (y - zmp_y)\n        \n        return [dx, ddx, dy, ddy]\n    \n    def simulate_trajectory(self, initial_state, zmp_trajectory, time_points):\n        """\n        Simulate CoM trajectory given ZMP reference\n        \n        Args:\n            initial_state: [x0, vx0, y0, vy0] initial CoM state\n            zmp_trajectory: Function that returns [zmp_x, zmp_y] for time t\n            time_points: Array of time points to simulate\n        \n        Returns:\n            Solution array with CoM trajectory\n        """\n        def wrapped_dynamics(state, t):\n            zmp_pos = zmp_trajectory(t)\n            return self.dynamics(state, t, zmp_pos)\n        \n        solution = odeint(wrapped_dynamics, initial_state, time_points)\n        return solution\n    \n    def calculate_capture_point(self, com_pos, com_vel):\n        """\n        Calculate capture point - where to step to stop the robot\n        \n        Args:\n            com_pos: [x, y] current CoM position\n            com_vel: [vx, vy] current CoM velocity\n            \n        Returns:\n            [x_cp, y_cp] capture point coordinates\n        """\n        x_com, y_com = com_pos\n        vx_com, vy_com = com_vel\n        \n        capture_point_x = x_com + vx_com / self.omega\n        capture_point_y = y_com + vy_com / self.omega\n        \n        return np.array([capture_point_x, capture_point_y])\n\n# Example usage\nlipm = LinearInvertedPendulum(com_height=0.85)\n\n# Define a simple ZMP trajectory (constant ZMP for 1 second)\ndef zmp_ref(t):\n    return np.array([0.0, 0.0])  # Constant ZMP at origin\n\n# Initial conditions: CoM at (0.1, 0.05) with some velocity\ninitial_state = [0.1, 0.2, 0.05, 0.1]  # [x_pos, x_vel, y_pos, y_vel]\n\n# Time vector (10 seconds at 100Hz)\ntime_points = np.linspace(0, 3, 300)\n\n# Simulate\nsolution = lipm.simulate_trajectory(initial_state, zmp_ref, time_points)\n\n# Calculate capture point at the beginning\ncapture_point = lipm.calculate_capture_point(\n    [initial_state[0], initial_state[2]],  # x, y position\n    [initial_state[1], initial_state[3]]   # vx, vy velocity\n)\n\nprint(f"Initial capture point: ({capture_point[0]:.3f}, {capture_point[1]:.3f})")\nprint(f"Final CoM position: ({solution[-1, 0]:.3f}, {solution[-1, 2]:.3f})")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"walking-pattern-generation",children:"Walking Pattern Generation"}),"\n",(0,o.jsx)(n.h3,{id:"preview-control-approach",children:"Preview Control Approach"}),"\n",(0,o.jsx)(n.p,{children:"Preview control uses future ZMP references to generate stable CoM trajectories:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from scipy.linalg import solve_discrete_are\nimport matplotlib.pyplot as plt\n\nclass PreviewController:\n    def __init__(self, com_height=0.8, dt=0.01, preview_window=2.0):\n        """\n        Initialize preview controller\n        \n        Args:\n            com_height: Estimated CoM height\n            dt: Control time step\n            preview_window: How far ahead to look (in seconds)\n        """\n        self.com_height = com_height\n        self.gravity = 9.81\n        self.dt = dt\n        self.omega = np.sqrt(self.gravity / com_height)\n        \n        # Number of steps to look ahead\n        self.preview_steps = int(preview_window / dt)\n        \n        # Discrete state-space matrices for x-axis (same for y-axis)\n        # State: x = [com_pos, com_vel]\n        self.A = np.array([\n            [1, dt],\n            [self.omega**2 * dt, 1]\n        ])\n        \n        self.B = np.array([0, -self.omega**2 * dt])\n        \n        # Output matrix: measure ZMP position\n        self.C = np.array([1, -1/(self.omega**2)])  # ZMP = x - (1/\u03c9\xb2)*\u1e8d\n        \n        # Design LQR controller\n        Q = np.array([[100, 0], [0, 1]])  # State cost\n        R = 1  # Control cost\n        \n        # Solve discrete algebraic Riccati equation\n        P = solve_discrete_are(self.A.T, self.C.T, Q, R)\n        \n        # Calculate LQR gain\n        self.K = np.array([1]) / (self.B.T @ P @ self.B + R) @ self.B.T @ P @ self.A\n    \n    def compute_control(self, current_state, zmp_reference_sequence):\n        """\n        Compute control using preview control law\n        \n        Args:\n            current_state: Current state [x, vx]\n            zmp_reference_sequence: Sequence of future ZMP references\n            \n        Returns:\n            Control input\n        """\n        # Feedback term\n        feedback_control = -self.K @ current_state\n        \n        # Preview term (feedforward)\n        preview_control = 0.0\n        \n        for k in range(min(len(zmp_reference_sequence), self.preview_steps)):\n            # Calculate preview gain for step k\n            A_pow = np.linalg.matrix_power(self.A, k)\n            C_A_pow_B = self.C @ A_pow @ self.B\n            \n            # Weight decreases with preview horizon\n            weight = np.exp(-0.1 * k)  # Exponential discounting\n            \n            # Calculate preview contribution\n            if k < len(zmp_reference_sequence):\n                preview_control += weight * (zmp_reference_sequence[k] - self.C @ A_pow @ current_state)\n        \n        return feedback_control + preview_control\n    \n    def generate_walking_trajectory(self, step_length=0.3, step_height=0.15, step_duration=1.0, steps=4):\n        """\n        Generate complete walking trajectory using preview control\n        \n        Args:\n            step_length: Forward distance per step\n            step_height: Maximum foot lift height\n            step_duration: Time per step\n            steps: Number of steps to generate\n            \n        Returns:\n            Dictionary with CoM and foot trajectories\n        """\n        total_time = steps * step_duration\n        time_points = np.arange(0, total_time, self.dt)\n        \n        # Initialize state\n        state = np.array([0.0, 0.0])  # [com_pos, com_vel]\n        \n        # Trajectory arrays\n        com_positions = []\n        com_velocities = []\n        zmp_positions = []\n        \n        # Generate ZMP reference for walking (alternating support)\n        zmp_ref = self.generate_zmp_reference(step_length, step_duration, total_time)\n        \n        # Simulate walking\n        for t in time_points:\n            idx = int(t / self.dt)\n            if idx >= len(zmp_ref):\n                break\n                \n            # Get preview window of ZMP references\n            end_preview_idx = min(idx + self.preview_steps, len(zmp_ref))\n            zmp_preview = zmp_ref[idx:end_preview_idx]\n            \n            # Compute control\n            u = self.compute_control(state, zmp_preview)\n            \n            # Update state using discrete dynamics\n            state = self.A @ state + self.B * u\n            \n            # Calculate resulting ZMP\n            current_zmp = self.C @ state\n            \n            # Store values\n            com_positions.append(state[0])\n            com_velocities.append(state[1])\n            zmp_positions.append(current_zmp)\n        \n        # Generate foot trajectories synchronized with CoM\n        left_foot_x, right_foot_x = self.generate_foot_trajectories(\n            step_length, step_duration, steps, time_points\n        )\n        \n        return {\n            "time": time_points,\n            "com_position": np.array(com_positions),\n            "com_velocity": np.array(com_velocities),\n            "zmp_position": np.array(zmp_positions),\n            "left_foot_x": left_foot_x,\n            "right_foot_x": right_foot_x,\n            "step_times": [i * step_duration for i in range(steps)]\n        }\n    \n    def generate_zmp_reference(self, step_length, step_duration, total_time):\n        """\n        Generate ZMP reference trajectory for walking\n        """\n        num_points = int(total_time / self.dt)\n        zmp_ref = np.zeros(num_points)\n        \n        for i in range(num_points):\n            t = i * self.dt\n            step_num = int(t / step_duration)\n            \n            # Alternate ZMP between feet support\n            if step_num % 2 == 0:  # Left foot support\n                zmp_ref[i] = -0.05  # Slightly left of center\n            else:  # Right foot support\n                zmp_ref[i] = 0.05   # Slightly right of center\n            \n            # Add forward progression\n            zmp_ref[i] += (step_num * step_length * 0.8)  # Scaled forward\n        \n        return zmp_ref\n    \n    def generate_foot_trajectories(self, step_length, step_duration, steps, time_array):\n        """\n        Generate foot trajectories synchronized with CoM\n        """\n        left_foot_x = np.zeros_like(time_array)\n        right_foot_x = np.zeros_like(time_array)\n        \n        for i, t in enumerate(time_array):\n            step_num = int(t / step_duration)\n            step_progress = (t % step_duration) / step_duration\n            \n            # Calculate foot positions based on current step and phase\n            if step_num % 2 == 0:  # Left foot swing\n                # Left foot trajectory\n                left_foot_x[i] = self.swing_trajectory(step_progress, step_num * step_length, (step_num + 1) * step_length)\n                \n                # Right foot stays in place during left foot swing\n                right_foot_x[i] = step_num * step_length\n            else:  # Right foot swing\n                # Right foot trajectory\n                right_foot_x[i] = self.swing_trajectory(step_progress, step_num * step_length, (step_num + 1) * step_length)\n                \n                # Left foot stays in place during right foot swing\n                left_foot_x[i] = step_num * step_length\n        \n        return left_foot_x, right_foot_x\n    \n    def swing_trajectory(self, progress, start_pos, end_pos):\n        """\n        Generate foot swing trajectory using smooth interpolation\n        """\n        # Use 5th-order polynomial for smooth acceleration/deceleration\n        # and zero velocity/acceleration at start/end\n        if progress < 0:\n            return start_pos\n        if progress > 1:\n            return end_pos\n            \n        # 5th order polynomial coefficients (ensures smooth start/end)\n        # s(t) = a0 + a1*t + a2*t^2 + a3*t^3 + a4*t^4 + a5*t^5\n        s = (-20*(progress**3) + 30*(progress**4) - 10*(progress**5))\n        \n        return start_pos + s * (end_pos - start_pos)\n\n# Example usage\npreview_ctrl = PreviewController(com_height=0.85, dt=0.01)\n\n# Generate walking trajectory\nwalking_traj = preview_ctrl.generate_walking_trajectory(\n    step_length=0.3,\n    step_height=0.15,\n    step_duration=1.0,\n    steps=4\n)\n\nprint(f"Generated trajectory for {len(walking_traj[\'step_times\'])} steps")\nprint(f"Final CoM position: {walking_traj[\'com_position\'][-1]:.3f} m")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"whole-body-control-framework",children:"Whole-Body Control Framework"}),"\n",(0,o.jsx)(n.p,{children:"For complex humanoid robots, whole-body controllers coordinate all joints to achieve multiple simultaneous objectives:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom scipy.optimize import minimize\n\nclass WholeBodyController:\n    def __init__(self, robot_model):\n        self.robot_model = robot_model  # Kinematic/dynamic model\n        self.tasks = []  # Priority-ordered tasks\n        self.weights = []  # Task weights\n        \n    def add_task(self, task_function, priority, weight=1.0):\n        """\n        Add a control task with priority and weight\n        \n        Args:\n            task_function: Function that returns task error\n            priority: Integer priority (lower number = higher priority)\n            weight: Weight for this task in optimization\n        """\n        self.tasks.append((priority, task_function, weight))\n        # Sort by priority (ascending - higher priority first)\n        self.tasks.sort(key=lambda x: x[0])\n    \n    def compute_control(self, current_state, reference_state):\n        """\n        Compute whole-body control using hierarchical optimization\n        \n        Args:\n            current_state: Current robot state (joint positions, velocities)\n            reference_state: Desired state for all joints\n            \n        Returns:\n            Joint commands to achieve all tasks\n        """\n        # Organize tasks by priority\n        high_priority_tasks = [(f, w) for p, f, w in self.tasks if p == 1]\n        mid_priority_tasks = [(f, w) for p, f, w in self.tasks if p == 2]\n        low_priority_tasks = [(f, w) for p, f, w in self.tasks if p == 3]\n        \n        # Higher priority tasks are solved first\n        # For this example, we\'ll use a simplified sequential approach\n        \n        # Start with base posture (lowest priority)\n        base_command = self.generate_posture_command(current_state, reference_state)\n        \n        # Add balance command (higher priority)\n        balance_command = self.compute_balance_adjustment(current_state)\n        \n        # Add task-specific commands\n        task_commands = []\n        for task_func, weight in high_priority_tasks + mid_priority_tasks:\n            task_cmd = task_func(current_state)\n            task_commands.append(weight * task_cmd)\n        \n        # Combine all commands (with priority-based weighting)\n        final_command = base_command + balance_command\n        for cmd in task_commands:\n            final_command += cmd\n        \n        return final_command\n    \n    def generate_posture_command(self, current_state, reference_state):\n        """\n        Generate command to maintain desired posture\n        """\n        # Simple PD control for posture maintenance\n        posture_error = reference_state["joint_positions"] - current_state["joint_positions"]\n        posture_command = 5.0 * posture_error + 1.0 * reference_state["joint_velocities"]  # PD controller\n        return posture_command\n    \n    def compute_balance_adjustment(self, current_state):\n        """\n        Compute adjustments needed for balance maintenance\n        """\n        # Use ZMP controller to compute balance adjustments\n        zmp_ctrl = ZMPController(com_height=0.85)\n        \n        # Get CoM state\n        com_pos = current_state["com_position"]\n        com_acc = current_state["com_acceleration"]\n        \n        # Calculate current ZMP\n        current_zmp = zmp_ctrl.calculate_zmp(com_pos, com_acc)\n        \n        # Desired ZMP (usually center of support polygon)\n        desired_zmp = np.array([0.0, 0.0])\n        \n        # Compute balance correction\n        dt = 0.01  # Control time step\n        balance_correction = zmp_ctrl.balance_control(current_zmp, desired_zmp, dt)\n        \n        # Convert balance correction to joint commands\n        # This would involve inverse kinematics/dynamics\n        # For now, return a simple representation\n        joint_correction = np.zeros(len(current_state["joint_positions"]))\n        \n        # Apply correction to ankle, hip, and trunk joints for balance\n        if len(joint_correction) >= 6:\n            # Ankle joints (if available)\n            joint_correction[-2] = balance_correction[0] * 0.1  # x direction\n            joint_correction[-1] = balance_correction[1] * 0.1  # y direction\n        \n        return joint_correction\n    \n    def compute_task_jacobian(self, task_type, configuration):\n        """\n        Compute Jacobian for a specific task (e.g., end-effector position)\n        \n        Args:\n            task_type: Type of task (\'position\', \'orientation\', etc.)\n            configuration: Joint configuration\n            \n        Returns:\n            Jacobian matrix\n        """\n        # This would implement the actual kinematic Jacobian calculation\n        # For this example, return a placeholder\n        n_joints = len(configuration)\n        if task_type == \'position\':\n            # 3D position task -> 3 x n_joints Jacobian\n            return np.random.rand(3, n_joints)  # Placeholder\n        elif task_type == \'orientation\':\n            # 3D orientation task -> 3 x n_joints Jacobian\n            return np.random.rand(3, n_joints)  # Placeholder\n        else:\n            return np.zeros((1, n_joints))\n\n# Example usage with a simple robot model\nclass SimpleRobotModel:\n    def __init__(self, num_joints=12):\n        self.num_joints = num_joints\n        self.joint_limits = np.tile([-2.5, 2.5], (num_joints, 1))  # Joint limits\n        self.mass_matrix = np.eye(num_joints) * 1.0  # Simplified mass matrix\n\nsimple_robot = SimpleRobotModel(num_joints=12)\nwb_controller = WholeBodyController(simple_robot)\n\n# Add tasks in order of priority\nwb_controller.add_task(lambda state: np.zeros(12), priority=3, weight=0.1)  # Posture maintenance (low priority)\nwb_controller.add_task(lambda state: np.zeros(12), priority=2, weight=1.0)  # Manipulation task (mid priority)\nwb_controller.add_task(lambda state: np.zeros(12), priority=1, weight=10.0)  # Balance maintenance (high priority)\n\n# Current and reference state (simplified)\ncurrent_state = {\n    "joint_positions": np.random.rand(12),\n    "joint_velocities": np.random.rand(12),\n    "com_position": np.array([0.0, 0.0, 0.85]),\n    "com_acceleration": np.array([0.1, 0.05, 0.0])\n}\n\nreference_state = {\n    "joint_positions": np.zeros(12),\n    "joint_velocities": np.zeros(12),\n}\n\n# Compute control\ncontrol_command = wb_controller.compute_control(current_state, reference_state)\nprint(f"Generated control command with {len(control_command)} joints")\nprint(f"Sample command values: {control_command[:5]}")\n\n# Visualization of walking trajectory\nplt.figure(figsize=(12, 8))\n\n# Plot CoM trajectory\nplt.subplot(2, 2, 1)\nplt.plot(walking_traj["time"], walking_traj["com_position"], label="CoM X", linewidth=2)\nplt.plot(walking_traj["time"], walking_traj["zmp_position"], label="ZMP X", linestyle="--")\nplt.xlabel("Time (s)")\nplt.ylabel("Position (m)")\nplt.title("Center of Mass and ZMP Trajectory")\nplt.legend()\nplt.grid(True)\n\n# Plot foot trajectories\nplt.subplot(2, 2, 2)\nplt.plot(walking_traj["time"], walking_traj["left_foot_x"], label="Left Foot", linewidth=2)\nplt.plot(walking_traj["time"], walking_traj["right_foot_x"], label="Right Foot", linewidth=2)\nplt.axhline(y=0, color=\'gray\', linestyle=\'--\', alpha=0.5, label="Start position")\nplt.xlabel("Time (s)")\nplt.ylabel("Position (m)")\nplt.title("Foot Trajectories")\nplt.legend()\nplt.grid(True)\n\n# Plot CoM velocity\nplt.subplot(2, 2, 3)\nplt.plot(walking_traj["time"], walking_traj["com_velocity"], linewidth=2)\nplt.xlabel("Time (s)")\nplt.ylabel("Velocity (m/s)")\nplt.title("Center of Mass Velocity")\nplt.grid(True)\n\n# Show step timing\nplt.subplot(2, 2, 4)\nfor step_time in walking_traj["step_times"]:\n    plt.axvline(x=step_time, color=\'red\', linestyle=\':\', alpha=0.7)\nplt.plot(walking_traj["time"], [0]*len(walking_traj["time"]), alpha=0)  # Invisible baseline\nplt.xlabel("Time (s)")\nplt.title("Step Timing")\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"stability-analysis-and-control",children:"Stability Analysis and Control"}),"\n",(0,o.jsx)(n.h3,{id:"lyapunov-stability-for-walking",children:"Lyapunov Stability for Walking"}),"\n",(0,o.jsx)(n.p,{children:"Lyapunov functions can be used to analyze and ensure stability of walking controllers:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class LyapunovWalkingStability:\n    def __init__(self, com_height=0.85, gravity=9.81):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        \n    def lyapunov_function(self, state):\n        """\n        Define Lyapunov function for walking stability\n        \n        State: [x_com, y_com, vx_com, vy_com, zmp_x, zmp_y]\n        """\n        x_com, y_com, vx_com, vy_com = state[:4]\n        zmp_x, zmp_y = state[4:6]\n        \n        # Lyapunov function for LIPM: V = \xbd(\u010bom\xb2 + \u03c9\xb2(com - zmp)\xb2)\n        energy_term = 0.5 * (vx_com**2 + vy_com**2)  # Kinetic energy part\n        potential_term = 0.5 * self.omega**2 * ((x_com - zmp_x)**2 + (y_com - zmp_y)**2)\n        \n        return energy_term + potential_term\n    \n    def lyapunov_derivative(self, state, state_derivative):\n        """\n        Calculate Lyapunov function derivative\n        \n        Args:\n            state: Current system state\n            state_derivative: Time derivative of state\n        """\n        x_com, y_com, vx_com, vy_com = state[:4]\n        zmp_x, zmp_y = state[4:6]\n        \n        xdot, ydot, vxdot, vydot = state_derivative[:4]\n        zmp_xdot, zmp_ydot = state_derivative[4:6]\n        \n        # Derivative of kinetic energy part\n        kinetic_dv = vx_com * vxdot + vy_com * vydot\n        \n        # Derivative of potential energy part\n        potential_dv = (self.omega**2 * \n                       ((x_com - zmp_x)*(vx_com - zmp_xdot) + \n                        (y_com - zmp_y)*(vy_com - zmp_ydot)))\n        \n        return kinetic_dv + potential_dv\n    \n    def is_asymptotically_stable(self, state, state_derivative, tolerance=0.01):\n        """\n        Check if system is asymptotically stable based on Lyapunov analysis\n        """\n        V = self.lyapunov_function(state)\n        Vdot = self.lyapunov_derivative(state, state_derivative)\n        \n        # For asymptotic stability: V > 0 and Vdot < 0\n        return V > tolerance and Vdot < -tolerance\n\n# Example usage\nstability_analyzer = LyapunovWalkingStability(com_height=0.85)\n\n# Current state (simplified)\ncurrent_state = np.array([0.05, 0.02, 0.1, 0.05, 0.01, 0.0])  # [x_com, y_com, vx_com, vy_com, zmp_x, zmp_y]\nstate_deriv = np.array([0.1, 0.05, -0.5, -0.2, 0.0, 0.0])   # [\u1e8b, \u1e8f, v\u0307x, v\u0307y, \u017cmp_x, \u017cmp_y]\n\nlyapunov_value = stability_analyzer.lyapunov_function(current_state)\nlyapunov_derivative = stability_analyzer.lyapunov_derivative(current_state, state_deriv)\nis_stable = stability_analyzer.is_asymptotically_stable(current_state, state_deriv)\n\nprint(f"Lyapunov function value: {lyapunov_value:.4f}")\nprint(f"Lyapunov derivative: {lyapunov_derivative:.4f}")\nprint(f"System asymptotically stable: {is_stable}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"adaptive-control-for-humanoid-robots",children:"Adaptive Control for Humanoid Robots"}),"\n",(0,o.jsx)(n.h3,{id:"model-reference-adaptive-control-mrac",children:"Model Reference Adaptive Control (MRAC)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class ModelReferenceAdaptiveController:\n    def __init__(self, reference_model_params, initial_controller_params):\n        """\n        Initialize MRAC system\n        \n        Args:\n            reference_model_params: Desired closed-loop dynamics\n            initial_controller_params: Initial estimates for controller params\n        """\n        self.reference_model = reference_model_params\n        self.controller_params = initial_controller_params\n        self.adaptation_rate = 0.01  # Learning rate\n        \n        # Storage for tracking errors and parameters\n        self.state_error = 0\n        self.param_error = 0\n        self.integration_term = 0\n    \n    def update_model_reference(self, desired_response, actual_response):\n        """\n        Update reference model based on desired and actual responses\n        """\n        # In practice, this would involve more complex reference model adjustment\n        pass\n    \n    def adapt_parameters(self, tracking_error, regressor_vector):\n        """\n        Adapt controller parameters based on tracking error\n        \n        Args:\n            tracking_error: Difference between desired and actual output\n            regressor_vector: Input vector that determines parameter adaptation\n        """\n        # Gradient descent adaptation law: \u03b8\u0307 = -\u03b3 \xd7 \u03c6 \xd7 e\n        param_adjustment = -self.adaptation_rate * regressor_vector * tracking_error\n        self.controller_params += param_adjustment\n        \n        return self.controller_params\n    \n    def compute_control(self, state_error, input_signal):\n        """\n        Compute control using current parameters\n        """\n        # Simple parameterized controller: u = \u03b8^T \xd7 \u03c6(x,u)\n        return self.controller_params.T @ input_signal\n\n# Example implementation for joint control\nclass AdaptiveJointController:\n    def __init__(self, joint_name, initial_params=np.array([1.0, 0.5])):\n        self.joint_name = joint_name\n        self.mrac = ModelReferenceAdaptiveController(\n            reference_model_params={\'natural_frequency\': 10, \'damping_ratio\': 0.7},\n            initial_controller_params=initial_params\n        )\n        \n    def update(self, desired_position, actual_position, dt=0.01):\n        """\n        Update controller with new measurements\n        """\n        # Calculate tracking error\n        tracking_error = desired_position - actual_position\n        \n        # Define regressor vector (function of state that determines adaptation)\n        regressor = np.array([actual_position, tracking_error])\n        \n        # Adapt parameters based on error\n        updated_params = self.mrac.adapt_parameters(tracking_error, regressor)\n        \n        # Compute new control command\n        control_signal = np.array([desired_position, tracking_error])\n        control_output = self.mrac.compute_control(tracking_error, control_signal)\n        \n        return control_output, tracking_error\n\n# Example usage\nadaptive_ctrl = AdaptiveJointController("left_knee", initial_params=np.array([1.5, 0.8]))\n\n# Simulate control loop\ndesired_pos = 0.5  # Desired joint position\nactual_pos = 0.2   # Current joint position\n\ncontrol_out, error = adaptive_ctrl.update(desired_pos, actual_pos)\nprint(f"Adaptive control output: {control_out:.4f}")\nprint(f"Tracking error: {error:.4f}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"safety-and-fault-tolerance",children:"Safety and Fault Tolerance"}),"\n",(0,o.jsx)(n.h3,{id:"balance-recovery-control",children:"Balance Recovery Control"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class BalanceRecoveryController:\n    def __init__(self, zmp_controller, com_height=0.85):\n        self.zmp_controller = zmp_controller\n        self.com_height = com_height\n        self.gravity = 9.81\n        self.omega = np.sqrt(self.gravity / com_height)\n        \n        # Thresholds for emergency actions\n        self.angle_threshold = 0.5  # 28.6 degrees\n        self.velocity_threshold = 1.0\n        self.zmp_threshold = 0.3  # 30cm outside support\n        \n        # Recovery strategies\n        self.recovery_modes = {\n            'ankle_strategy': {'priority': 1, 'max_torque': 50},\n            'hip_strategy': {'priority': 2, 'max_torque': 100},\n            'step_strategy': {'priority': 3, 'enabled': True}\n        }\n    \n    def assess_imminent_fall(self, robot_state):\n        \"\"\"\n        Assess if robot is at risk of falling\n        \n        Args:\n            robot_state: Dictionary with robot status information\n            \n        Returns:\n            Dictionary with fall risk assessment\n        \"\"\"\n        risk_assessment = {\n            'fall_risk_level': 'low',  # low, medium, high, imminent\n            'risk_factors': [],\n            'recovery_needed': False\n        }\n        \n        # Check IMU angles (tilt)\n        imu_angles = robot_state.get('imu_angles', [0, 0, 0])\n        roll, pitch = imu_angles[0], imu_angles[1]\n        \n        if abs(roll) > self.angle_threshold or abs(pitch) > self.angle_threshold:\n            risk_assessment['risk_factors'].append('excessive_tilt')\n            risk_assessment['fall_risk_level'] = 'high'\n            risk_assessment['recovery_needed'] = True\n        \n        # Check angular velocity\n        angular_vel = robot_state.get('angular_velocity', [0, 0, 0])\n        ang_roll_vel, ang_pitch_vel = angular_vel[0], angular_vel[1]\n        \n        if abs(ang_roll_vel) > self.velocity_threshold or abs(ang_pitch_vel) > self.velocity_threshold:\n            risk_assessment['risk_factors'].append('high_angular_velocity')\n            if risk_assessment['fall_risk_level'] == 'low':\n                risk_assessment['fall_risk_level'] = 'medium'\n            risk_assessment['recovery_needed'] = True\n        \n        # Check ZMP position relative to support polygon\n        current_zmp = robot_state.get('zmp', [0, 0])\n        support_polygon = {'x_range': [-0.1, 0.1], 'y_range': [-0.15, 0.15]}\n        \n        zmp_x, zmp_y = current_zmp\n        x_min, x_max = support_polygon['x_range']\n        y_min, y_max = support_polygon['y_range']\n        \n        zmp_margin_x = min(abs(zmp_x - x_min), abs(zmp_x - x_max))\n        zmp_margin_y = min(abs(zmp_y - y_min), abs(zmp_y - y_max))\n        \n        if zmp_margin_x < 0.05 or zmp_margin_y < 0.05:  # Less than 5cm margin\n            risk_assessment['risk_factors'].append('zmp_near_boundary')\n            risk_assessment['fall_risk_level'] = 'high'\n            risk_assessment['recovery_needed'] = True\n        elif zmp_margin_x < 0.1 or zmp_margin_y < 0.1:  # Less than 10cm margin\n            risk_assessment['risk_factors'].append('zmp_approaching_boundary')\n            if risk_assessment['fall_risk_level'] == 'low':\n                risk_assessment['fall_risk_level'] = 'medium'\n        \n        return risk_assessment\n    \n    def execute_recovery_strategy(self, risk_assessment, robot_state):\n        \"\"\"\n        Execute appropriate recovery strategy based on risk level\n        \"\"\"\n        if not risk_assessment['recovery_needed']:\n            return {'action': 'none', 'commands': {}}\n        \n        # Determine appropriate recovery strategy\n        highest_priority = max([self.recovery_modes[mode]['priority'] \n                               for mode in self.recovery_modes.keys()])\n        \n        recovery_commands = {}\n        \n        if risk_assessment['fall_risk_level'] in ['high', 'imminent']:\n            # Immediate action needed\n            if self.recovery_modes['step_strategy']['enabled']:\n                # Step to new support location\n                step_target = self.calculate_safe_step_location(robot_state)\n                recovery_commands['step'] = step_target\n                return {'action': 'step_recovery', 'commands': recovery_commands}\n            \n            # If step not available, try hip strategy\n            elif self.recovery_modes['hip_strategy']['priority'] <= highest_priority:\n                hip_command = self.calculate_hip_correction(robot_state)\n                recovery_commands['hip_torques'] = hip_command\n                return {'action': 'hip_recovery', 'commands': recovery_commands}\n        \n        # For medium risk, use ankle strategy\n        else:\n            ankle_command = self.calculate_ankle_correction(robot_state)\n            recovery_commands['ankle_torques'] = ankle_command\n            return {'action': 'ankle_recovery', 'commands': recovery_commands}\n    \n    def calculate_ankle_correction(self, robot_state):\n        \"\"\"\n        Calculate ankle torques for small balance corrections\n        \"\"\"\n        # Simple PD controller for ankle balance\n        current_zmp = robot_state.get('zmp', [0, 0])\n        desired_zmp = robot_state.get('desired_zmp', [0, 0])\n        \n        zmp_error = np.array(desired_zmp) - np.array(current_zmp)\n        \n        # Convert ZMP error to ankle torques (simplified model)\n        ankle_torques = 200 * zmp_error  # Proportional gain\n        ankle_torques = np.clip(ankle_torques, \n                               -self.recovery_modes['ankle_strategy']['max_torque'],\n                                self.recovery_modes['ankle_strategy']['max_torque'])\n        \n        return ankle_torques\n    \n    def calculate_hip_correction(self, robot_state):\n        \"\"\"\n        Calculate hip torques for larger balance corrections\n        \"\"\"\n        # Similar approach but with higher torques and different kinematics\n        current_com = robot_state.get('com_position', [0, 0, 0.85])\n        desired_com = robot_state.get('desired_com', [0, 0, 0.85])\n        \n        com_error = np.array(desired_com)[:2] - np.array(current_com)[:2]  # x,y only\n        \n        hip_torques = 500 * com_error  # Higher gain for hip strategy\n        hip_torques = np.clip(hip_torques,\n                             -self.recovery_modes['hip_strategy']['max_torque'],\n                              self.recovery_modes['hip_strategy']['max_torque'])\n        \n        return hip_torques\n    \n    def calculate_safe_step_location(self, robot_state):\n        \"\"\"\n        Calculate safe step location to expand support polygon\n        \"\"\"\n        current_zmp = robot_state.get('zmp', [0, 0])\n        current_com = robot_state.get('com_position', [0, 0, 0.85])\n        current_com_vel = robot_state.get('com_velocity', [0, 0, 0])\n        \n        # Use capture point concept to determine where to step\n        capture_point_x = current_com[0] + current_com_vel[0] / self.omega\n        capture_point_y = current_com[1] + current_com_vel[1] / self.omega\n        \n        # Choose step location near capture point but within reasonable range\n        step_x = np.clip(capture_point_x, current_zmp[0] - 0.4, current_zmp[0] + 0.4)\n        step_y = np.clip(capture_point_y, current_zmp[1] - 0.3, current_zmp[1] + 0.3)\n        \n        return [step_x, step_y, 0.0]  # [x, y, z]\n\n# Example usage\nzmp_ctrl = ZMPController(com_height=0.85)\nrecovery_ctrl = BalanceRecoveryController(zmp_ctrl)\n\n# Simulate a potentially unstable state\nrobot_state = {\n    'imu_angles': [0.6, 0.4, 0],  # Excessive roll and pitch (34.4\xb0 and 22.9\xb0)\n    'angular_velocity': [1.2, 0.8, 0.1],  # High angular velocities\n    'zmp': [0.2, 0.1],  # ZMP near boundary\n    'com_position': [0.05, 0.02, 0.85],\n    'com_velocity': [0.3, 0.1, 0],\n    'desired_zmp': [0.0, 0.0],\n    'desired_com': [0.0, 0.0, 0.85]\n}\n\nrisk_assessment = recovery_ctrl.assess_imminent_fall(robot_state)\nrecovery_action = recovery_ctrl.execute_recovery_strategy(risk_assessment, robot_state)\n\nprint(f\"Risk assessment: {risk_assessment['fall_risk_level']}\")\nprint(f\"Recovery action: {recovery_action['action']}\")\nif 'step' in recovery_action['commands']:\n    print(f\"Recommended step location: {recovery_action['commands']['step']}\")\n"})}),"\n",(0,o.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Implement a balance controller that can maintain stability when external forces are applied to the robot."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Design a walking trajectory generator that can adapt to uneven terrain."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Using the educational AI agents, explore how different control strategies (ZMP-based vs. whole-body control vs. learning-based) affect the stability and performance of the humanoid robot."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The next section will explore how these control systems are implemented in real hardware and the challenges of the sim-to-real transfer."})]})}function _(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>s});var r=t(6540);const o={},a=r.createContext(o);function i(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);