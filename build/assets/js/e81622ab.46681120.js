"use strict";(globalThis.webpackChunkeducational_ai_humanoid_robotics=globalThis.webpackChunkeducational_ai_humanoid_robotics||[]).push([[744],{5026:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"ros/fundamentals","title":"ROS 2 Fundamentals for Humanoid Robotics","description":"Overview","source":"@site/docs/ros/fundamentals.md","sourceDirName":"ros","slug":"/ros/fundamentals","permalink":"/educational-ai-humanoid-robotics/docs/ros/fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/educational-ai-humanoid-robotics/educational-ai-humanoid-robotics.github.io/tree/main/packages/create-docusaurus/templates/shared/docs/ros/fundamentals.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Educational AI & Humanoid Robotics: Complete Course","permalink":"/educational-ai-humanoid-robotics/docs/intro"},"next":{"title":"Nodes, Topics, and Services in ROS 2","permalink":"/educational-ai-humanoid-robotics/docs/ros/nodes-topics-services"}}');var s=i(4848),r=i(8453);const t={sidebar_position:2},a="ROS 2 Fundamentals for Humanoid Robotics",l={},c=[{value:"Overview",id:"overview",level:2},{value:"ROS 2 vs ROS 1: Key Differences",id:"ros-2-vs-ros-1-key-differences",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Nodes",id:"nodes",level:3},{value:"Topics and Messages",id:"topics-and-messages",level:3},{value:"Services",id:"services",level:3},{value:"Actions",id:"actions",level:3},{value:"Setting Up a Humanoid Robot in ROS 2",id:"setting-up-a-humanoid-robot-in-ros-2",level:2},{value:"URDF Models",id:"urdf-models",level:3},{value:"Launch Files",id:"launch-files",level:3},{value:"Best Practices for Humanoid Robotics",id:"best-practices-for-humanoid-robotics",level:2},{value:"Modular Design",id:"modular-design",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ros-2-fundamentals-for-humanoid-robotics",children:"ROS 2 Fundamentals for Humanoid Robotics"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Robot Operating System 2 (ROS 2) is a flexible framework for writing robot software. It's a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robot platforms. In the context of humanoid robotics, ROS 2 provides the communication infrastructure needed for the complex sensorimotor loops and distributed processing requirements."}),"\n",(0,s.jsx)(n.h2,{id:"ros-2-vs-ros-1-key-differences",children:"ROS 2 vs ROS 1: Key Differences"}),"\n",(0,s.jsx)(n.p,{children:"ROS 2 addresses several limitations of the original ROS, making it more suitable for humanoid robotics applications:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real-Time Support"}),": Critical for humanoid robot control systems that require deterministic timing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Improved Security"}),": Essential when humanoid robots interact with humans in educational settings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Better Multi-Robot Support"}),": Necessary for scenarios involving multiple humanoid robots"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Quality of Service (QoS) Settings"}),": Allows specification of delivery guarantees for different types of data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"DDS-Based Communication"}),": Provides more robust and configurable communication patterns"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsx)(n.h3,{id:"nodes",children:"Nodes"}),"\n",(0,s.jsx)(n.p,{children:"In ROS 2, a node is a process that performs computation. Each node in a ROS graph can be written in different programming languages (C++, Python, etc.) and can run on different machines. For humanoid robots, common nodes include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Sensor processing nodes (IMU, cameras, LIDAR)"}),"\n",(0,s.jsx)(n.li,{children:"Control nodes (walking, manipulation, balance)"}),"\n",(0,s.jsx)(n.li,{children:"Perception nodes (object recognition, localization)"}),"\n",(0,s.jsx)(n.li,{children:"Planning nodes (motion planning, path planning)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"topics-and-messages",children:"Topics and Messages"}),"\n",(0,s.jsx)(n.p,{children:"Topics are named buses over which nodes exchange messages. In humanoid robotics, common topics include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/joint_states"})," - Current joint positions, velocities, and efforts"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/cmd_vel"})," - Velocity commands for base movement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/sensor_msgs/Image"})," - Camera image data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/tf"})," - Transform data for coordinate frames"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"services",children:"Services"}),"\n",(0,s.jsx)(n.p,{children:"Services provide a request/reply communication pattern. Common services in humanoid robotics include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/set_parameters"})," - Dynamically configure robot parameters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/get_plans"})," - Request motion plans from planning services"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/calibrate"})," - Service for sensor calibration"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"actions",children:"Actions"}),"\n",(0,s.jsx)(n.p,{children:"Actions are a goal-based communication pattern suitable for long-running tasks. In humanoid robotics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/move_base"})," - Send navigation goals"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/joint_trajectory"})," - Execute complex joint movement sequences"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"/pick_place"})," - Perform manipulation tasks"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"setting-up-a-humanoid-robot-in-ros-2",children:"Setting Up a Humanoid Robot in ROS 2"}),"\n",(0,s.jsx)(n.h3,{id:"urdf-models",children:"URDF Models"}),"\n",(0,s.jsx)(n.p,{children:"Unified Robot Description Format (URDF) is an XML format for representing robot models. A humanoid robot URDF typically includes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Kinematic tree describing joint connections"}),"\n",(0,s.jsx)(n.li,{children:"Physical properties (mass, inertia)"}),"\n",(0,s.jsx)(n.li,{children:"Visual and collision properties"}),"\n",(0,s.jsx)(n.li,{children:"Sensor mountings"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="humanoid_robot">\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.5 0.5 0.5"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.5 0.5 0.5"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="1.0" ixy="0.0" ixz="0.0" iyy="1.0" iyz="0.0" izz="1.0"/>\n    </inertial>\n  </link>\n  \n  \x3c!-- Add additional links for legs, arms, head, etc. --\x3e\n  <link name="left_leg">\n    <visual>\n      <geometry>\n        <cylinder length="0.6" radius="0.05"/>\n      </geometry>\n    </visual>\n  </link>\n  \n  <joint name="base_to_left_leg" type="fixed">\n    <parent link="base_link"/>\n    <child link="left_leg"/>\n    <origin xyz="0 -0.2 -0.3" rpy="0 0 0"/>\n  </joint>\n</robot>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"launch-files",children:"Launch Files"}),"\n",(0,s.jsx)(n.p,{children:"Launch files allow you to start multiple nodes with a single command. For a humanoid robot:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<launch>\n  \x3c!-- Start robot state publisher --\x3e\n  <node pkg="robot_state_publisher" \n        exec="robot_state_publisher" \n        name="robot_state_publisher">\n    <param name="robot_description" \n           value="$(var robot_description_file)"/>\n  </node>\n\n  \x3c!-- Start joint state publisher --\x3e\n  <node pkg="joint_state_publisher_gui" \n        exec="joint_state_publisher_gui" \n        name="joint_state_publisher_gui"/>\n\n  \x3c!-- Start simulation or hardware interface --\x3e\n  <include file="$(find-pkg-share my_humanoid_description)/launch/gazebo.launch.py"/>\n</launch>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices-for-humanoid-robotics",children:"Best Practices for Humanoid Robotics"}),"\n",(0,s.jsx)(n.h3,{id:"modular-design",children:"Modular Design"}),"\n",(0,s.jsx)(n.p,{children:"Break down complex humanoid behaviors into smaller, reusable nodes. For example:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Separate perception from planning from control"}),"\n",(0,s.jsx)(n.li,{children:"Create specialized nodes for different locomotion patterns"}),"\n",(0,s.jsx)(n.li,{children:"Use service nodes for calibration and configuration"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(n.p,{children:"Implement robust error handling in all nodes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Establish timeouts for communication"}),"\n",(0,s.jsx)(n.li,{children:"Handle sensor failures gracefully"}),"\n",(0,s.jsx)(n.li,{children:"Implement safe states for robot control"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Minimize message passing between nodes running on the same machine"}),"\n",(0,s.jsx)(n.li,{children:"Use appropriate QoS settings for real-time requirements"}),"\n",(0,s.jsx)(n.li,{children:"Profile nodes to identify bottlenecks"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),"\n",(0,s.jsx)(n.p,{children:"Create a simple ROS 2 package that implements a basic walking pattern for a simulated humanoid robot:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Use the educational AI to generate ROS 2 code for a walking controller"}),"\n",(0,s.jsx)(n.li,{children:"Simulate the walking pattern in the simulation environment"}),"\n",(0,s.jsx)(n.li,{children:"Observe the robot's behavior and joint trajectories"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The next section will cover ROS 2 packages and workspaces in greater detail, including how to structure code for humanoid robot applications."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var o=i(6540);const s={},r=o.createContext(s);function t(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);